{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/unifyai/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ivy\n",
    "import ivy_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import ivy\n",
    "\n",
    "\n",
    "def conv3x3(\n",
    "    in_planes: int,\n",
    "    out_planes: int,\n",
    "    stride: int = 1,\n",
    "    dilations: int = 1,\n",
    ") -> ivy.Conv2D:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return ivy.Conv2D(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        [3, 3],\n",
    "        stride,\n",
    "        dilations,\n",
    "        with_bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> ivy.Conv2D:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return ivy.Conv2D(in_planes, out_planes, [1, 1], stride, 0, with_bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(ivy.Module):\n",
    "    \"\"\"\n",
    "    Basic block used in the ResNet architecture.\n",
    "\n",
    "    Args::\n",
    "        inplanes (int): Number of input channels.\n",
    "        planes (int): Number of output channels.\n",
    "        stride (int): Stride value for the block. Defaults to 1.\n",
    "        downsample (Optional[ivy.Module]): Downsample module for the block.\n",
    "        base_width (int): The base width of the block. Defaults to 64.\n",
    "        dilation (int): Dilation rate of the block. Defaults to 1.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[ivy.Module] = None,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        self.norm_layer = ivy.BatchNorm2D\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        if base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports base_width=64\")\n",
    "\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.stride = stride\n",
    "        self.downsample = downsample\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "    def _build(self, *args, **kwargs):\n",
    "        self.conv1 = conv3x3(self.inplanes, self.planes, self.stride)\n",
    "        self.bn1 = self.norm_layer(self.planes)\n",
    "        self.relu = ivy.ReLU()\n",
    "        self.conv2 = conv3x3(self.planes, self.planes)\n",
    "        self.bn2 = self.norm_layer(self.planes)\n",
    "        self.downsample = self.downsample\n",
    "        self.stride = self.stride\n",
    "\n",
    "    def _forward(self, x):\n",
    "        \"\"\"Forward pass method for the module.\"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(ivy.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck block used in the ResNet architecture.\n",
    "\n",
    "    Args::\n",
    "        inplanes (int): Number of input channels.\n",
    "        planes (int): Number of output channels.\n",
    "        stride (int): Stride value for the block. Defaults to 1.\n",
    "        downsample (Optional[ivy.Module]): Downsample module for the block.\n",
    "        base_width (int): The base width of the block. Defaults to 64.\n",
    "        dilation (int): Dilation rate of the block. Defaults to 1.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[ivy.Module] = None,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        self.norm_layer = ivy.BatchNorm2D\n",
    "        self.width = int(planes * (base_width / 64.0))\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "    def _build(self, *args, **kwargs):\n",
    "        self.conv1 = conv1x1(self.inplanes, self.width)\n",
    "        self.bn1 = self.norm_layer(self.width)\n",
    "        self.conv2 = conv3x3(self.width, self.width, self.stride, self.dilation)\n",
    "        self.bn2 = self.norm_layer(self.width)\n",
    "        self.conv3 = conv1x1(self.width, self.planes * self.expansion)\n",
    "        self.bn3 = self.norm_layer(self.planes * self.expansion)\n",
    "        self.relu = ivy.ReLU()\n",
    "        self.downsample = self.downsample\n",
    "\n",
    "    def _forward(self, x):\n",
    "        \"\"\"Forward pass method for the module.\"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _prune_keys(raw, ref, raw_keys_to_prune=[], ref_keys_to_prune=[]):\n",
    "    pruned_ref = {}\n",
    "    if raw_keys_to_prune:\n",
    "        raw = raw.cont_prune_keys(raw_keys_to_prune)\n",
    "    if ref_keys_to_prune:\n",
    "        pruned_ref = ref.cont_at_keys(ref_keys_to_prune)\n",
    "        ref = ref.cont_prune_keys(ref_keys_to_prune)\n",
    "    return raw, ref, pruned_ref\n",
    "\n",
    "\n",
    "def _map_weights(raw, ref, custom_mapping=None):\n",
    "    mapping = {}\n",
    "    for old_key, new_key in zip(\n",
    "        raw.cont_sort_by_key().cont_to_iterator_keys(),\n",
    "        ref.cont_sort_by_key().cont_to_iterator_keys(),\n",
    "    ):\n",
    "        new_mapping = new_key\n",
    "        if custom_mapping is not None:\n",
    "            new_mapping = custom_mapping(old_key, new_key)\n",
    "        mapping[old_key] = new_mapping\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_torch_weights(\n",
    "    url,\n",
    "    ref_model,\n",
    "    raw_keys_to_prune=[],\n",
    "    ref_keys_to_prune=[],\n",
    "    custom_mapping=None,\n",
    "    map_location=torch.device(\"cpu\"),\n",
    "):\n",
    "    ivy_torch = ivy.with_backend(\"torch\")\n",
    "    weights = torch.hub.load_state_dict_from_url(url, map_location=map_location)\n",
    "    ###\n",
    "    display(ivy.asarray(ivy.Container(weights)))\n",
    "\n",
    "\n",
    "    weights_raw = ivy.Container(\n",
    "        ivy_torch.to_numpy(ivy_torch.Container(weights)).cont_to_dict()\n",
    "    )\n",
    "    weights_raw, weights_ref, pruned_ref = _prune_keys(\n",
    "        weights_raw, ref_model.v, raw_keys_to_prune, ref_keys_to_prune\n",
    "    )\n",
    "    mapping = _map_weights(weights_raw, weights_ref, custom_mapping=custom_mapping)\n",
    "    w_clean = weights_raw.cont_restructure(mapping, keep_orig=False)\n",
    "    if ref_keys_to_prune:\n",
    "        w_clean = ivy.Container.cont_combine(w_clean, pruned_ref)\n",
    "    return ivy.asarray(w_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global\n",
    "from typing import List, Optional, Type, Union\n",
    "import builtins\n",
    "\n",
    "import ivy\n",
    "import ivy_models\n",
    "from ivy_models.resnet.layers import conv1x1, BasicBlock, Bottleneck\n",
    "from ivy_models.base import BaseSpec, BaseModel\n",
    "\n",
    "\n",
    "class ResNetSpec(BaseSpec):\n",
    "    \"\"\"\n",
    "    ResNetSpec class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        base_width: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "    ) -> None:\n",
    "        super(ResNetSpec, self).__init__(\n",
    "            block=block,\n",
    "            layers=layers,\n",
    "            num_classes=num_classes,\n",
    "            base_width=base_width,\n",
    "            replace_stride_with_dilation=replace_stride_with_dilation,\n",
    "        )\n",
    "\n",
    "\n",
    "class ResNet(BaseModel):\n",
    "    \"\"\"\n",
    "    Residual Neural Network (ResNet) architecture.\n",
    "\n",
    "    Args::\n",
    "        block (Type[Union[BasicBlock, Bottleneck]]):\n",
    "            The block type used in the ResNet architecture.\n",
    "        layers: List of integers specifying the number of blocks in each layer.\n",
    "        num_classes (int): Number of output classes. Defaults to 1000.\n",
    "        base_width (int): The base width of the ResNet. Defaults to 64.\n",
    "        replace_stride_with_dilation (Optional[List[bool]]):\n",
    "            List indicating whether to replace stride with dilation.\n",
    "        v (ivy.Container): Unused parameter. Can be ignored.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        base_width: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        spec=None,\n",
    "        v: ivy.Container = None,\n",
    "    ) -> None:\n",
    "        self.spec = (\n",
    "            spec\n",
    "            if spec and isinstance(spec, ResNetSpec)\n",
    "            else ResNetSpec(\n",
    "                block, layers, num_classes, base_width, replace_stride_with_dilation\n",
    "            )\n",
    "        )\n",
    "\n",
    "        super(ResNet, self).__init__(v=v)\n",
    "\n",
    "    def _build(self, *args, **kwargs):\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if self.spec.replace_stride_with_dilation is None:\n",
    "            self.spec.replace_stride_with_dilation = [False, False, False]\n",
    "\n",
    "        self.conv1 = ivy.Conv2D(3, self.inplanes, [7, 7], 2, 3, with_bias=False)\n",
    "        self.bn1 = ivy.BatchNorm2D(self.inplanes)\n",
    "        self.relu = ivy.ReLU()\n",
    "        self.maxpool = ivy.MaxPool2D(3, 2, 1)\n",
    "        self.layer1 = self._make_layer(self.spec.block, 64, self.spec.layers[0])\n",
    "        self.layer2 = self._make_layer(\n",
    "            self.spec.block,\n",
    "            128,\n",
    "            self.spec.layers[1],\n",
    "            stride=2,\n",
    "            dilate=self.spec.replace_stride_with_dilation[0],\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            self.spec.block,\n",
    "            256,\n",
    "            self.spec.layers[2],\n",
    "            stride=2,\n",
    "            dilate=self.spec.replace_stride_with_dilation[1],\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            self.spec.block,\n",
    "            512,\n",
    "            self.spec.layers[3],\n",
    "            stride=2,\n",
    "            dilate=self.spec.replace_stride_with_dilation[2],\n",
    "        )\n",
    "        self.avgpool = ivy.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = ivy.Linear(512 * self.spec.block.expansion, self.spec.num_classes)\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> ivy.Sequential:\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = ivy.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                ivy.BatchNorm2D(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,\n",
    "                planes,\n",
    "                stride,\n",
    "                downsample,\n",
    "                self.spec.base_width,\n",
    "                previous_dilation,\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    base_width=self.spec.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return ivy.Sequential(*layers)\n",
    "\n",
    "    @classmethod\n",
    "    def get_spec_class(self):\n",
    "        return ResNetSpec\n",
    "\n",
    "    def _forward(self, x):\n",
    "        dtype = x.dtype\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = ivy.asarray(x, dtype=dtype)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = ivy.permute_dims(x, (0, 3, 1, 2))\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet_torch_weights_mapping(old_key, new_key):\n",
    "    W_KEY = [\"conv1/weight\", \"conv2/weight\", \"conv3/weight\", \"downsample/0/weight\"]\n",
    "    new_mapping = new_key\n",
    "    if builtins.any([kc in old_key for kc in W_KEY]):\n",
    "        new_mapping = {\"key_chain\": new_key, \"pattern\": \"b c h w -> h w c b\"}\n",
    "    return new_mapping\n",
    "\n",
    "\n",
    "def resnet_18(pretrained=True):\n",
    "    \"\"\"ResNet-18 model\"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    if pretrained:\n",
    "        url = \"https://download.pytorch.org/models/resnet18-f37072fd.pth\"\n",
    "        w_clean = ivy_models.helpers.load_torch_weights(\n",
    "            url,\n",
    "            model,\n",
    "            raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "            custom_mapping=_resnet_torch_weights_mapping,\n",
    "        )\n",
    "        model.v = w_clean\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_34(pretrained=True):\n",
    "    \"\"\"ResNet-34 model\"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "    if pretrained:\n",
    "        url = \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\"\n",
    "        w_clean = load_torch_weights(\n",
    "            url,\n",
    "            model,\n",
    "            raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "            custom_mapping=_resnet_torch_weights_mapping,\n",
    "        )\n",
    "        model.v = w_clean\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_50(pretrained=True):\n",
    "    \"\"\"ResNet-50 model\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "    if pretrained:\n",
    "        url = \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\"\n",
    "        w_clean = ivy_models.helpers.load_torch_weights(\n",
    "            url,\n",
    "            model,\n",
    "            raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "            custom_mapping=_resnet_torch_weights_mapping,\n",
    "        )\n",
    "        model.v = w_clean\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_101(pretrained=True):\n",
    "    \"\"\"ResNet-101 model\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "    if pretrained:\n",
    "        url = \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\"\n",
    "        w_clean = ivy_models.helpers.load_torch_weights(\n",
    "            url,\n",
    "            model,\n",
    "            raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "            custom_mapping=_resnet_torch_weights_mapping,\n",
    "        )\n",
    "        model.v = w_clean\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_152(pretrained=True):\n",
    "    \"\"\"ResNet-152 model\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "    if pretrained:\n",
    "        url = \"https://download.pytorch.org/models/resnet152-f82ba261.pth\"\n",
    "        w_clean = ivy_models.helpers.load_torch_weights(\n",
    "            url,\n",
    "            model,\n",
    "            raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "            custom_mapping=_resnet_torch_weights_mapping,\n",
    "        )\n",
    "        model.v = w_clean\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ivy\n",
    "import random\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "# Enable x64 support in JAX\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "from ivy_models_tests import helpers\n",
    "from ivy_models import (\n",
    "    resnet_18,\n",
    "    resnet_34,\n",
    "    resnet_50,\n",
    "    resnet_101,\n",
    "    resnet_152,\n",
    ")\n",
    "\n",
    "\n",
    "VARIANTS = {\n",
    "    \"r18\": resnet_18,\n",
    "    \"r34\": resnet_34,\n",
    "    \"r50\": resnet_50,\n",
    "    \"r101\": resnet_101,\n",
    "    \"r152\": resnet_152,\n",
    "}\n",
    "\n",
    "LOGITS = {\n",
    "    \"r18\": np.array([0.7069, 0.2663, 0.0231]),\n",
    "    \"r34\": np.array([0.8507, 0.1351, 0.0069]),\n",
    "    \"r50\": np.array([0.3429, 0.0408, 0.0121]),\n",
    "    \"r101\": np.array([0.7834, 0.0229, 0.0112]),\n",
    "    \"r152\": np.array([0.8051, 0.0473, 0.0094]),\n",
    "}\n",
    "\n",
    "\n",
    "load_weights = random.choice([False, True])\n",
    "model_var = random.choice(list(VARIANTS.keys()))\n",
    "model = VARIANTS[model_var](pretrained=load_weights)\n",
    "v = ivy.to_numpy(model.v)\n",
    "\n",
    "\n",
    "def test_resnet_img_classification(device, fw):\n",
    "    \"\"\"Test ResNet-18 image classification.\"\"\"\n",
    "    num_classes = 1000\n",
    "    batch_shape = [1]\n",
    "    this_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "    # Load image\n",
    "    img = ivy.asarray(\n",
    "        helpers.load_and_preprocess_img(\n",
    "            os.path.join(this_dir, \"..\", \"..\", \"images\", \"cat.jpg\"),\n",
    "            256,\n",
    "            224,\n",
    "            data_format=\"NHWC\",\n",
    "            to_ivy=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model.v = ivy.asarray(v)\n",
    "    output = model(img)\n",
    "\n",
    "    # Cardinality test\n",
    "    assert output.shape == tuple([ivy.to_scalar(batch_shape), num_classes])\n",
    "\n",
    "    # Value test\n",
    "    if load_weights:\n",
    "        output = output[0]\n",
    "        true_indices = ivy.array([282, 281, 285])\n",
    "        calc_indices = ivy.argsort(output, descending=True)[:3]\n",
    "\n",
    "        assert np.array_equal(true_indices, calc_indices)\n",
    "\n",
    "        true_logits = LOGITS[model_var]\n",
    "        calc_logits = np.take(\n",
    "            helpers.np_softmax(ivy.to_numpy(output)), ivy.to_numpy(calc_indices)\n",
    "        )\n",
    "\n",
    "        assert np.allclose(true_logits, calc_logits, rtol=0.005)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
